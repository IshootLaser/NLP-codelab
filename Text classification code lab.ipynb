{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "欢迎！\n",
    "\n",
    "在这个code lab里，你会学习如何创造简单的text embedding，然后用神经网络来进行文本信息分类。\n",
    "\n",
    "文本信息分类是一个常见的NLP任务。它可以帮助我们自动理解文本信息，寻找相似信息和进行信息推送。\n",
    "\n",
    "在本次练习里，我们会使用StackOverflow questions数据集。我们会训练一个文本信息分类器，并用它来分类文本中的问题所涉及到的编程语言。\n",
    "\n",
    "首先，我们import所需的library。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "import nltk\n",
    "try:\n",
    "    from nltk.corpus import stopwords\n",
    "except:\n",
    "    nltk.download('stopwords')\n",
    "    from nltk.corpus import stopwords\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看并了解数据集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags:  ['c#' 'php' 'c_cpp' 'python' 'ruby' 'java' 'javascript' 'vb' 'r' 'swift']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>title</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2168983</th>\n",
       "      <td>43837842</td>\n",
       "      <td>Efficient Algorithm to compose valid expressio...</td>\n",
       "      <td>python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084095</th>\n",
       "      <td>15747223</td>\n",
       "      <td>Why does this basic thread program fail with C...</td>\n",
       "      <td>c_cpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049020</th>\n",
       "      <td>15189594</td>\n",
       "      <td>Link to scroll to top not working</td>\n",
       "      <td>javascript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200466</th>\n",
       "      <td>3273927</td>\n",
       "      <td>Is it possible to implement ping on windows ph...</td>\n",
       "      <td>c#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200249</th>\n",
       "      <td>17684551</td>\n",
       "      <td>GLSL normal mapping issue</td>\n",
       "      <td>c_cpp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          post_id                                              title  \\\n",
       "2168983  43837842  Efficient Algorithm to compose valid expressio...   \n",
       "1084095  15747223  Why does this basic thread program fail with C...   \n",
       "1049020  15189594                  Link to scroll to top not working   \n",
       "200466    3273927  Is it possible to implement ping on windows ph...   \n",
       "1200249  17684551                          GLSL normal mapping issue   \n",
       "\n",
       "                tag  \n",
       "2168983      python  \n",
       "1084095       c_cpp  \n",
       "1049020  javascript  \n",
       "200466           c#  \n",
       "1200249       c_cpp  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_size = 200000\n",
    "stackoverflow_df = pd.read_csv('tagged_posts.tsv', sep='\\t').sample(sample_size, random_state=0)\n",
    "tags = pd.read_csv('tagged_posts.tsv', sep='\\t')['tag'].unique()\n",
    "print('tags: ', tags)\n",
    "stackoverflow_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通常，我们会对文字信息进行简化（去除复数，用词根代替衍生词等等）。\n",
    "\n",
    "定义预处理方法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_prepare(text):\n",
    "    \"\"\"Performs tokenization and simple preprocessing.\"\"\"\n",
    "    \n",
    "    replace_by_space_re = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "    bad_symbols_re = re.compile('[^0-9a-z #+_]')\n",
    "    stopwords_set = set(stopwords.words('english'))\n",
    "\n",
    "    text = text.lower()\n",
    "    text = replace_by_space_re.sub(' ', text)\n",
    "    text = bad_symbols_re.sub('', text)\n",
    "    text = ' '.join([x for x in text.split() if x and x not in stopwords_set])\n",
    "    \n",
    "    tokenizer = nltk.tokenize.TreebankWordTokenizer()\n",
    "    tokens = tokenizer.tokenize(text.strip())\n",
    "    \n",
    "    stemmer = nltk.stem.PorterStemmer()\n",
    "    return ' '.join(stemmer.stem(token) for token in tokens)\n",
    "\n",
    "def one_hot(tag, tags = tags):\n",
    "    oh = tags == tag\n",
    "    return np.uint8(np.array(oh))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试预处理结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "programm love python\n",
      "[0 1 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(text_prepare('What do pRogRammers love ABOUT@ python?'))\n",
    "print(one_hot('php'))\n",
    "print(one_hot('ruby'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对整个数据集进行预处理："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>title</th>\n",
       "      <th>tag</th>\n",
       "      <th>title_processed</th>\n",
       "      <th>oh_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2168983</th>\n",
       "      <td>43837842</td>\n",
       "      <td>Efficient Algorithm to compose valid expressio...</td>\n",
       "      <td>python</td>\n",
       "      <td>effici algorithm compos valid express specif t...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084095</th>\n",
       "      <td>15747223</td>\n",
       "      <td>Why does this basic thread program fail with C...</td>\n",
       "      <td>c_cpp</td>\n",
       "      <td>basic thread program fail clang pass g++</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049020</th>\n",
       "      <td>15189594</td>\n",
       "      <td>Link to scroll to top not working</td>\n",
       "      <td>javascript</td>\n",
       "      <td>link scroll top work</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200466</th>\n",
       "      <td>3273927</td>\n",
       "      <td>Is it possible to implement ping on windows ph...</td>\n",
       "      <td>c#</td>\n",
       "      <td>possibl implement ping window phone 7</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200249</th>\n",
       "      <td>17684551</td>\n",
       "      <td>GLSL normal mapping issue</td>\n",
       "      <td>c_cpp</td>\n",
       "      <td>glsl normal map issu</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          post_id                                              title  \\\n",
       "2168983  43837842  Efficient Algorithm to compose valid expressio...   \n",
       "1084095  15747223  Why does this basic thread program fail with C...   \n",
       "1049020  15189594                  Link to scroll to top not working   \n",
       "200466    3273927  Is it possible to implement ping on windows ph...   \n",
       "1200249  17684551                          GLSL normal mapping issue   \n",
       "\n",
       "                tag                                    title_processed  \\\n",
       "2168983      python  effici algorithm compos valid express specif t...   \n",
       "1084095       c_cpp           basic thread program fail clang pass g++   \n",
       "1049020  javascript                               link scroll top work   \n",
       "200466           c#              possibl implement ping window phone 7   \n",
       "1200249       c_cpp                               glsl normal map issu   \n",
       "\n",
       "                                 oh_tag  \n",
       "2168983  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]  \n",
       "1084095  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1049020  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]  \n",
       "200466   [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1200249  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stackoverflow_df['title_processed'] = stackoverflow_df['title'].apply(text_prepare)\n",
    "stackoverflow_df['oh_tag'] = stackoverflow_df['tag'].apply(one_hot)\n",
    "stackoverflow_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将数据集分成训练集和测试集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['implement scrollview python kivi' 'jqueri drag drop text div smaller div'\n",
      " 'jdk16 + understand err file' 'node travers can not null hibern updat'\n",
      " 'subqueri nspredic'\n",
      " 'stack trace wekacorewekaexcept wekaclassifiersfunctionssmo enough train instanc class label requir 1 provid 0'\n",
      " 'get number line file text c' 'use deleteallonsubmit tabl primari key'\n",
      " 'java simpl implement command pattern oncomplet callback'\n",
      " 'c # tcp server client crosscommun requir']\n",
      "[[0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "X = stackoverflow_df['title_processed'].values\n",
    "y = np.array(stackoverflow_df['oh_tag'].values.tolist())\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.05, random_state = 42)\n",
    "# 查看结果\n",
    "print(X_train[:10])\n",
    "print(y_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对文本信息进行text embedding处理，将文本信息根据上下文单词出现的频率进行向量化："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_features(X_train, X_test):\n",
    "    tfidf_vectorizer = TfidfVectorizer(ngram_range = (1, 5), token_pattern = '(\\S+)', max_df = 0.9, min_df = 5)\n",
    "    X_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "    X_test = tfidf_vectorizer.transform(X_test)\n",
    "    pickle.dump(tfidf_vectorizer, open('tfidf_vectorizer.pkl', 'wb'))\n",
    "    \n",
    "    return X_train, X_test, tfidf_vectorizer.vocabulary_, tfidf_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<190000x41030 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1530064 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf, X_test_tfidf, tf_idf_vocab, tfidf_trans = tfidf_features(X_train, X_test)\n",
    "X_train_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建mini batch："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(X, y, batch_size = 32):\n",
    "    shape = X.shape[0]\n",
    "    for i in range(0, shape, batch_size):\n",
    "        yield X[i:i+batch_size].toarray(), y[i:i+batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建全连接神经网络架构:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(dtype = tf.float32, shape = (None, X_train_tfidf.shape[1]))\n",
    "y = tf.placeholder(dtype = tf.float32, shape = (None, 10))\n",
    "\n",
    "num_neurons = [1024, 128, 10]\n",
    "\n",
    "fc = tf.layers.dense(X, num_neurons[0], activation = tf.nn.relu)\n",
    "for i in num_neurons[1:-2]:\n",
    "    fc = tf.layers.dense(fc, i, activation = tf.nn.relu)\n",
    "fc = tf.layers.dense(fc, num_neurons[-1], activation = tf.nn.sigmoid)\n",
    "\n",
    "loss = tf.losses.log_loss(labels = y, predictions = fc, reduction = tf.losses.Reduction.NONE)\n",
    "cost = tf.reduce_mean(loss, axis = -1)\n",
    "optimizer = tf.train.AdamOptimizer(0.001)\n",
    "train_op = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练分类器并测试准确率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 validation accuracy is 0.8061102236421726\n",
      "Epoch 2 validation accuracy is 0.7875399361022364\n",
      "Epoch 4 validation accuracy is 0.7846445686900958\n",
      "Epoch 5 validation accuracy is 0.7807507987220448\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 6\n",
    "batch_size = 32\n",
    "bg_train = batch_generator(X_train_tfidf, y_train, batch_size)\n",
    "bg_test = batch_generator(X_test_tfidf, y_test, batch_size)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    for X_train_, y_train_ in bg_train:\n",
    "        sess.run(train_op, feed_dict = {X: X_train_, y: y_train_})\n",
    "        \n",
    "    if (i % 2 == 0) or (i == num_epochs - 1):\n",
    "        ov_acc = []\n",
    "        for X_test_, y_test_ in bg_test:\n",
    "            y_pred_ = sess.run(fc, feed_dict = {X: X_test_})\n",
    "            acc = accuracy_score(np.argmax(y_test_, axis = -1), np.argmax(y_pred_, axis = -1))\n",
    "            ov_acc.append(acc)\n",
    "        print('Epoch {} validation accuracy is {}'.format(i, np.mean(ov_acc)))\n",
    "        \n",
    "    bg_train = batch_generator(X_train_tfidf, y_train, batch_size)\n",
    "    bg_test = batch_generator(X_test_tfidf, y_test, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test case prediction is 'c_cpp'\n"
     ]
    }
   ],
   "source": [
    "# 测试结果\n",
    "test_case = tfidf_trans.transform([text_prepare('How to use recursion in c++?')]).toarray().astype(np.float32)\n",
    "y_pred = sess.run(fc, feed_dict = {X: test_case})\n",
    "print('Test case prediction is \\'{}\\''.format(tags[np.argmax(y_pred)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用简单的全连接模型，平均测试准确率为80%。\n",
    "\n",
    "我们可以用StarSpace来创造更复杂的embeddings，并用RNN来理解、分类问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 载入预训练好的StarSpace embedding\n",
    "embeddings = pickle.load(open('starspace_embedding.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils functions\n",
    "def build_encode(x, max_len, emb = embeddings, emb_dim = 100):\n",
    "    emb_ls = []\n",
    "    for word in x.split():\n",
    "        try:\n",
    "            emb_ls.append(emb[word])\n",
    "        except:\n",
    "            emb_ls.append(np.zeros((emb_dim,)))\n",
    "            \n",
    "    padding = np.zeros((max_len, emb_dim))\n",
    "    if len(emb_ls) > 0:\n",
    "        padding[:len(emb_ls)] = np.array(emb_ls)\n",
    "        return padding\n",
    "    else:\n",
    "        return padding\n",
    "\n",
    "def RNN_batch_generator(X, y, max_len, batch_size = 32):\n",
    "    shape = X.shape[0]\n",
    "    for i in range(0, shape, batch_size):\n",
    "        x_mini_batch = np.array([build_encode(x, max_len) for x in X[i:i+batch_size]]).astype(np.float32)\n",
    "        y_mini_batch = y[i:i+batch_size]\n",
    "        yield x_mini_batch, np.float32(y_mini_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创造一个简单的RNN with LSTM cell。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = np.max([len(x.split()) for x in X_train])\n",
    "emb_dim = 100\n",
    "X_rnn = tf.placeholder(dtype = tf.float32, shape = (None, max_len, emb_dim))\n",
    "y_rnn = tf.placeholder(dtype = tf.float32, shape = (None, 10))\n",
    "\n",
    "cell = tf.nn.rnn_cell.BasicLSTMCell(100, reuse = tf.AUTO_REUSE) \n",
    "outputs, state = tf.nn.dynamic_rnn(cell, \n",
    "                                   X_rnn, \n",
    "                                   dtype = tf.float32)\n",
    "y_pred = tf.layers.dense(state[0], 10, activation = tf.nn.sigmoid)\n",
    "\n",
    "loss_rnn = tf.losses.log_loss(labels = y_rnn, predictions = y_pred, reduction = tf.losses.Reduction.NONE)\n",
    "cost_rnn = tf.reduce_mean(loss_rnn, axis = -1)\n",
    "optimizer_rnn = tf.train.AdamOptimizer(0.001)\n",
    "train_op_rnn = optimizer_rnn.minimize(cost_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 validation accuracy is 0.8413538338658147\n",
      "Epoch 2 validation accuracy is 0.8483426517571885\n",
      "Epoch 4 validation accuracy is 0.8498402555910544\n",
      "Epoch 5 validation accuracy is 0.8501397763578274\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 6\n",
    "batch_size = 32\n",
    "bg_train = RNN_batch_generator(X_train, y_train, max_len, batch_size)\n",
    "bg_test = RNN_batch_generator(X_test, y_test, max_len, batch_size)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    for X_train_, y_train_ in bg_train:\n",
    "        sess.run(train_op_rnn, feed_dict = {X_rnn: X_train_, y_rnn: y_train_})\n",
    "        \n",
    "    if (i % 2 == 0) or (i == num_epochs - 1):\n",
    "        ov_acc = []\n",
    "        for X_test_, y_test_ in bg_test:\n",
    "            y_pred_ = sess.run(y_pred, feed_dict = {X_rnn: X_test_})\n",
    "            acc = accuracy_score(np.argmax(y_test_, axis = -1), np.argmax(y_pred_, axis = -1))\n",
    "            ov_acc.append(acc)\n",
    "        print('Epoch {} validation accuracy is {}'.format(i, np.mean(ov_acc)))\n",
    "        \n",
    "    bg_train = RNN_batch_generator(X_train, y_train, max_len, batch_size)\n",
    "    bg_test = RNN_batch_generator(X_test, y_test, max_len, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试训练结果：<br>\n",
    "case 1：训练准确性<br>\n",
    "case 2：问题之间的相似性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test case prediction is python\n"
     ]
    }
   ],
   "source": [
    "# Test case 1\n",
    "test_case = build_encode('How to use list comprehension?', 23)\n",
    "test_case = np.expand_dims(test_case.astype(np.float32), 0)\n",
    "test_pred = sess.run(y_pred, feed_dict = {X_rnn: test_case})\n",
    "print('Test case prediction is {}'.format(tags[np.argmax(test_pred)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine distances between c_cpp and python problems: [[ 0.61002129]] and [[ 0.54072559]]\n",
      "Cosine distance between python problems: [[ 0.07263857]]\n"
     ]
    }
   ],
   "source": [
    "# Test case 2\n",
    "test_case_0 = build_encode('How do you set, clear, and toggle a single bit?', 23) #C/C++ problem\n",
    "test_case_0 = np.expand_dims(test_case_0.astype(np.float32), 0)\n",
    "\n",
    "test_case_1 = build_encode('Maximum recursion depth in python?', 23)\n",
    "test_case_1 = np.expand_dims(test_case_1.astype(np.float32), 0)\n",
    "\n",
    "test_case_2 = build_encode('How to use list comprehension?', 23)\n",
    "test_case_2 = np.expand_dims(test_case_2.astype(np.float32), 0)\n",
    "\n",
    "test_emb_0 = np.squeeze(sess.run(state[1], feed_dict = {X_rnn: test_case_0})).reshape(1,-1)\n",
    "test_emb_1 = np.squeeze(sess.run(state[1], feed_dict = {X_rnn: test_case_1})).reshape(1,-1)\n",
    "test_emb_2 = np.squeeze(sess.run(state[1], feed_dict = {X_rnn: test_case_2})).reshape(1,-1)\n",
    "\n",
    "compare_0_1 = cosine_distances(test_emb_0, test_emb_1)\n",
    "compare_0_2 = cosine_distances(test_emb_0, test_emb_2)\n",
    "compare_1_2 = cosine_distances(test_emb_1, test_emb_2)\n",
    "\n",
    "print('Cosine distances between c_cpp and python problems: {} and {}'.format(compare_0_1, compare_0_2))\n",
    "print('Cosine distance between python problems: {}'.format(compare_1_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从测试结果我们可以看到，准确率明显上升。\n",
    "\n",
    "总结：\n",
    "\n",
    "1. 文本信息分类是一个常见的NLP任务。\n",
    "2. 它的常见流程是：a) 文字预处理，b) 生成单词的embedding（基于计数方法或者训练方法），c) 训练模型。\n",
    "3. 由训练生成的embedding更能反映一个单词的意义。同时，它的表现方式更为密集（相对于计数方法生成的稀疏向量）。\n",
    "4. RNN是NLP领域常见的模型，性能往往比普通的全连接模型更好。\n",
    "5. RNN中的隐藏状态可能可以反映出文本之间的相似度关系。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
